---
output:
  html_document:
    keep_md: yes
---
```{r}
library(caret)
```

## Q1

```{r}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test) 

vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
```

```{r, cache=TRUE}
set.seed(33833)
rf.fit <- train(y ~ ., data = vowel.train, method = 'rf')
```

```{r, cache=TRUE}
gbm.fit <- train(y ~ ., data = vowel.train, method = 'gbm', verbose = FALSE)
```

```{r}
rf.predict <- predict(rf.fit, newdata = vowel.test)
gbm.predict <- predict(gbm.fit, newdata = vowel.test)
```

```{r}
rf.confusion <- confusionMatrix(rf.predict, vowel.test$y)
gbm.confusion <- confusionMatrix(gbm.predict, vowel.test$y)
```

Accuracy for RF is `r rf.confusion$overall[1]`.
Accuracy for GBM is `r gbm.confusion$overall[1]`.

Agreed accuracy is:
```{r}
mean(rf.predict == gbm.predict)
```

## Q2

```{r}
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
```

```{r, cache=TRUE}
model <- list()
set.seed(62433)
model$rf <- train(diagnosis ~ ., data = training, method = 'rf')
model$gbm <- train(diagnosis ~ ., data = training, method = 'gbm', verbose = FALSE)
model$lda <- train(diagnosis ~ ., data = training, method = 'lda')
```

Compose the models:
```{r}
predictions <- list()
predictions$rf <- predict(model$rf, newdata = testing)
predictions$gbm <- predict(model$gbm, newdata = testing)
predictions$lda <- predict(model$lda, newdata = testing)
modelsDf <- data.frame(predictions$rf, predictions$gbm, predictions$lda, diagnosis = testing$diagnosis)

model$combo <- train(diagnosis ~ ., data = modelsDf, method = 'rf')
```

Compare the models:
```{r}
results <- resamples(model)
summary(results)
bwplot(results)
```

```{r}
confusionMatrix(predictions$rf, testing$diagnosis)$overall[1]
confusionMatrix(predictions$gbm, testing$diagnosis)$overall[1]
confusionMatrix(predictions$lda, testing$diagnosis)$overall[1]

predictions$combo <- predict(model$combo, modelsDf)
confusionMatrix(predictions$combo, testing$diagnosis)$overall[1]
```

## Q3

```{r}
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
```

```{r}
lasso.fit <- train(CompressiveStrength ~ ., data = training, method = 'lasso')
plot(lasso.fit$finalModel, xvar= 'penalty', use.color = TRUE)
```

## Q4

```{r}
#install.packages('lubridate')
library(lubridate)  # For year() function below
file = url("http://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
dat = read.csv(file)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstesting = ts(testing$visitsTumblr, start = end(tstrain))
```

```{r}
#install.packages('forecast')
library(forecast)
plot(tstrain)
```

```{r}
bats.fit <- bats(tstrain)
bats.fcast <- forecast(bats.fit, h = length(tstesting))
plot(bats.fcast); lines(tstesting, col='red')
accuracy(bats.fcast, tstesting)
mean(tstesting < bats.fcast$upper[,2] & tstesting > bats.fcast$lower[,1])
```

## Q5

```{r}
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
```

```{r}
library(e1071)
svm.fit <- svm(CompressiveStrength ~ ., data = training)
summary(svm.fit)
svm.pred <- predict(svm.fit, testing)
```

RMSE is `r sqrt(sum((svm.pred - testing$CompressiveStrength) ^ 2) / length(svm.pred))`

