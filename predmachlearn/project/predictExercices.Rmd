---
output:
  html_document:
    keep_md: yes
bibliography: wle.bib
---

## Project Objectives

This project is related to Human Activity Recognition and the goal is 
to analyze data from Weight Lifting Exercises [@velloso2013qualitative].

This data set contains several variables used to measure different characteristics
of a movement : coordinates in space, pitch, roll...

The objectives are:

* train a model on this dataset (in fact we will try 2 models Decision Tree and Random Forest, then choose the best model)
* validate the model against out of sample data
* submit the model to 20 test cases provided in th assignement


## Install libraries

First we will need some libraries:
```{r, cache=TRUE, message=FALSE, warning=FALSE}
options(repos = c('http://cran.rstudio.com'))
install.packages('caret')
install.packages('e1071')
install.packages('gbm')
install.packages('randomForest')
install.packages('doMC', dependencies = TRUE)
```

## Data loading

Then we load the data, and create the train set and test set (75% vs. 25%):
```{r,cache=TRUE}
source('loadData.R')
trainingUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
testingUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
  
loadDataFile(trainingUrl, "data/pml-training.csv", unzip=FALSE)
loadDataFile(testingUrl, "data/pml-testing.csv", unzip=FALSE)

data <- read.csv("data/pml-training.csv")
inTrain <- createDataPartition(y=data$classe, p=0.75, list=FALSE)

training <- data[inTrain,]
testing <- data[-inTrain,]

validation <- read.csv("data/pml-testing.csv")
```

The `validation` set will be used to submit test cases to the model.

Several columns contain lots of empty or NAs values:
```{r}
str(training)
```

So we filter the column with more than 95% of NAs:
```{r}
colnamesForFilter <- colnames(training)
colsPercent <- sapply(colnamesForFilter, function(x) {
    na <- is.na(training[,x]) | training[,x] == ''
    sum(na)/length(na)
})

trainingColnames <- names(which(colsPercent < 0.95))
```

The data is split on the `new_window` column between 2 sort of data:

* if `new_window` is true then the row contains aggregated data of the last frame
* if `new_window` is false, then the row contains instant measure

As the `validation` set contains only false `new_window`, we will filter our train set on this
value:

```{r}
trainingData <- training[training$new_window == 'no',trainingColnames[-c(1, 3:7, 61)]]
testingData <- testing[testing$new_window == 'no',trainingColnames[-c(1, 3:7, 61)]]
```

## Training model with Decision Tree

The first attempt is to train a model based on Decision Tree (with `rpart` package). We fit a model
to predict `classe` against all remaining variables:

```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(caret)
rpartModel <- list()
rpartModel$time <- system.time(rpartModel$fit <- train( classe ~ ., data=trainingData, method="rpart"))
rpartModel$predictions <- predict(rpartModel$fit, newdata = testingData)
rpartModel$confusionMatrix <- confusionMatrix(rpartModel$predictions, testingData$classe)
```

The model is trained in **`r rpartModel$time[3]`** seconds.

Below is a plot of the confusion matrix, calculated against an out of sample dataset (`testing`):
```{r}
library(ggplot2)
rpartModel$df <- as.data.frame(rpartModel$confusionMatrix$table)
qplot(data = rpartModel$df, x = Reference, y = Prediction,
      fill = Freq,
      geom = 'tile',
      main = "Confusion matrix for Decision Tree model") +
  geom_text(aes(label = Freq)) +
  scale_fill_gradient(low = "red", high = "blue")
```

We can see that the model fails to predict 'D' classe, we'll need to investigate this problem.
Result is quite poor with an accuracy of **`r rpartModel$confusionMatrix$overall[1]`**.

## Training model with Random Forests

Next we try with Random Forests model (`rf` package). Again, we try to fit the model based on the same formula:

```{r, cache=TRUE, message=FALSE, warning=FALSE}
require('doMC')
registerDoMC(cores = 2)
rfModel <- list()
rfModel$time <- system.time(rfModel$fit <- train( classe ~ ., data=trainingData, method="rf"))
rfModel$predictions <- predict(rfModel$fit, newdata = testingData)
rfModel$confusionMatrix <- confusionMatrix(rfModel$predictions, testingData$classe)
```

Model is trained in **`r rfModel$time[3]`** seconds, which is longer than previous training.

Below is a plot of the confusion matrix:
```{r}
rfModel$df <- as.data.frame(rfModel$confusionMatrix$table)
qplot(data = rfModel$df, x = Reference, y = Prediction,
      fill = Freq,
      geom = 'tile',
      main = "Confusion matrix for Random Forest model") +
  geom_text(aes(label = Freq)) +
  scale_fill_gradient(low = "red", high = "blue")
```

Result is excellent with an accuracy of **`r rfModel$confusionMatrix$overall[1]`**, so we will 
keep this one for the final validation phase

## Validation phase

We start by filtering the columns of the validation set:

```{r}
validationData <- validation[validation$new_window == 'no',trainingColnames[-c(1, 3:7, 60)]]
```

Then we use the Random Forest model to predict the outcome `classe`:
```{r, message=FALSE, warning=FALSE}
predictions <- predict(rfModel$fit, newdata = validationData)
predictions
```

```{r, echo=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
if(!file.exists('answers')) dir.create('answers')
setwd('answers')
pml_write_files(predictions)
```

## References


