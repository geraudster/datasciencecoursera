----
title: Analysis of types of severe weather events that have most impacted the population and the economics in the United States from 1950 to 2011
author: Géraud Dugé de Bernonville
date: June 22, 2014
output: pdf_document
----

# Analysis of types of severe weather events that have most impacted the population and the economics in the United States from 1950 to 2011

## Synopsis

In this report we aim to describe the types of severe weather events that had the most impact on the population and on the economics in the U.S. from 1950 to 2011.
To perform this analysis, we used data from the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database.
This database contains data from 1950 to 2011 that tracks major storms and weather events (like avalanche, dense fog, tsunami...).
More specifically, it contains data on public health impact (fatalities and injuries) and economics (crop and properties damages in dollars).
After cleaning the data, we will focus on the 10 most important types of events for each aspects (fatalities and injuries, crop damages, properties damages).
The data shows that health consequences are in the order of several hundred thousands (fatalities and injuries) and economical damages are in the order of hundreds of billions dollars.
The study also shows that storm events have different consequences on the public health and economics.
On the public health side, Tornadoes and excessive heat are most harmful and
on the economics side, floods and ouragans have greater consequences. 

## Loading libraries

Before we start, we load the required libraries:

``` {r}
library(R.utils) # used for bunzip2
library(ggplot2)
library(plyr)
library(reshape)
library(scales)
source("multiplot.R")
```

## Data Processing

* The data is located at https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2.
* The description is here: https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf
* The code book is here: http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Export-Format.docx

### Loading data

Let's retrieve and uncompress the data from the Coursera's site:

```{r,cache=TRUE}
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
datadir <- "data"
zipdatafile <- paste(datadir, "StormData.csv.bz2", sep="/")
if(!file.exists(zipdatafile)) {
    if(!file.exists(datadir)) { dir.create(datadir) }
    download.file(url, destfile=zipdatafile, method="curl")
}

datafile <- paste(datadir, "StormData.csv", sep="/")
bunzip2(zipdatafile, destname=datafile, remove=FALSE, overwrite=TRUE)
```

Then we load the data in R (might take several minutes...):
```{r,cache=TRUE}
data <- read.csv(datafile)
```

The data contains `r nrow(data)` observations of `r ncol(data)` variables. On our environment it takes `r format(object.size(data), units= "MB")` of memory.

Here is a small insight of what the data look like:
```{r}
str(data)
```

The interesting fields in this dataset are:

* EVTYPE: the type of severe event
* FATALITIES and INJURIES: the fatalities and injuries due to the event
* PROPDMG: estimated amount of damage to property (in $)
* CROPDMG: estimated amount of damage to crops (in $)
* PROPDMGEXP: the exponent to be applied. Levels are:
```{r}
levels(data$PROPDMGEXP)
```

* CROPDMGEXP: the exponent to be applied. Levels are:
```{r}
levels(data$CROPDMGEXP)
```

### Exponents

Concerning the exponents, we will ignore special characters (-, ?, +)
* B = billions
* M/m = millions
* K/k = thousands
* H/h = hundreds
* numeric value = 10^value

Let's create a function to calculate the correct amount given an exponent:
```{r}
# first we define a correspondance table for the unit
expUnitTable <- data.frame(unit=c("h", "k", "m", "b"), weight=c(10^2, 10^3, 10^6, 10^9))

# the function itself
calculateExponent <- function(value, exponent) {
    # we set the default value for a weight to 1, so we will keep the value as is
    weight <- 1
    exponentChar <- tolower(exponent)
    # check if the exponent is a number
    if(suppressWarnings(!is.na(as.numeric(exponentChar)))) {
        weight <- 10 ^ as.numeric(exponentChar)
    } else {
        # get the weight associated with the unit. If not present, we got a numeric(0)
        weight <- expUnitTable$weight[expUnitTable$unit == tolower(exponentChar)]
        
        # if the unit is not in the table, reset the default value
        if(length(weight) == 0) {
            weight <- 1;
        }
    }
    value * weight
}
```

### Tidy dataset preparation

We prepare two tidy datasets: one for analysing the most harmful events, and the other for analysing
the greatest economic consequences.
```{r,cache=TRUE}
dataForHarm <- data[c("EVTYPE", "FATALITIES", "INJURIES")]
dataForEconomics <- data[c("EVTYPE", "CROPDMG", "CROPDMGEXP", "PROPDMG", "PROPDMGEXP")]
```

As we are interesting in finding the most harmful events, we can clean 
our datasets by removing all zero or undefined values in the fields.
```{r}
tidyDataForHarm <- dataForHarm[ dataForHarm$FATALITIES != 0 & dataForHarm$INJURIES != 0,]
nrow(tidyDataForHarm)

tidyDataForEconomics <- dataForEconomics [ dataForEconomics$CROPDMG != 0 & dataForEconomics$PROPDMG != 0,]
nrow(tidyDataForEconomics)
```

Then we add 2 columns to the economics dataset that compute a usable form of the amount of damage:
```{r,cache=TRUE}
tidyDataForEconomics <- transform(tidyDataForEconomics,
                                  cropDmgAmount = mapply(calculateExponent,
                                                         as.numeric(CROPDMG),
                                                         CROPDMGEXP),
                                  propDmgAmount = mapply(calculateExponent,
                                                         as.numeric(PROPDMG),
                                                         PROPDMGEXP))
```

There are **`r length(levels(data$EVTYPE))`** different values of EVTYPE. It does not match the code book which describes 48 categories.
This difference can be explained by the fact that earlier values were not correctly normalized, and the
informations might be slightly incorrect.
For the purpose of this study we will not transform thos EVTYPEs and will takes the data as-is.

## Results

### Most harmful types of storm events

We will use the tidyDataForHarm dataset and will find the 10 most harmful events (total of injuries plus fatalities).

First we perform some aggregation based on the EVTYPE:
```{r}
aggregatesForHarm <- ddply(tidyDataForHarm, .(EVTYPE),
                           summarize,
                           fatalitiesTotal=sum(FATALITIES, na.rm=TRUE),
                           injuriesTotal=sum(INJURIES, na.rm=TRUE))

# Let's compute the total of injuries and fatalities
aggregatesForHarm$total <- aggregatesForHarm$fatalitiesTotal + aggregatesForHarm$injuriesTotal
```

Then we prepare a "long" dataset with the two group of variables:
```{r}
meltAggregatesHarmful <- melt(aggregatesForHarm, id=c("EVTYPE", "total"))
meltAggregatesHarmful <- transform(meltAggregatesHarmful, EVTYPE = reorder(EVTYPE, total))
top <- head(meltAggregatesHarmful[order(meltAggregatesHarmful$total, decreasing=TRUE),], 20)
top <- transform(top, variable = factor(variable, levels=c("fatalitiesTotal", "injuriesTotal"), labels=c("Fatalities", "Injuries")))
```

The top10 is shown below (the TORNADO injuries is far more greater than the other EVTYPEs, so we decided 
to cut the bar to have a better glimpse at the other EVTYPEs) :
```{r,fig.width=9}
gHarmful <- ggplot(top, aes(x=EVTYPE, fill=variable, y=value)) +
    geom_histogram(stat="identity") +
    coord_flip(ylim=c(0,10000)) +
    geom_text(data=top[2,], aes(x=EVTYPE, y=8000, label=paste(value, "injuries"))) +
    ggtitle(label="10 most harmful events in the U.S. from 1950 to 2011") +
    ylab("Total of injuries + fatalities") +
    xlab("Event type") +
    scale_fill_discrete(name="")
gHarmful
```

So here we can see that Tornadoes is the most harmful event, with `r top$value[1]` fatalities and `r format(top$value[2], scientific=FALSE)` injuries. Then comes the excessive heat (`r top$value[3]` fatalities and `r format(top$value[4], scientific=FALSE)` injuries) and flood (`r top$value[5]` fatalities and `r format(top$value[6], scientific=FALSE)` injuries).

### Most economical impact

For this part, we will distinguish the damages caused to the crops and the damages caused to the properties, 
because they are in different order of magnitude.

We start by aggregating the damages to crop and properties by EVTYPE:
```{r}
aggregatesForEco <- ddply(tidyDataForEconomics, .(EVTYPE),
                           summarize,
                           cropDmgAmountTotal=sum(cropDmgAmount, na.rm=TRUE),
                           propDmgAmountTotal=sum(propDmgAmount, na.rm=TRUE))
```

Then we prepare a long dataset:
```{r}
meltAggregatesEco <- melt(aggregatesForEco, id="EVTYPE")
meltAggregatesEcoSorted <- meltAggregatesEco[order(meltAggregatesEco$value, decreasing=TRUE),]
```

Next we retrieve the top 10 most economical damages:
```{r}
cropDamageTop10 <- meltAggregatesEcoSorted[meltAggregatesEcoSorted$variable == "cropDmgAmountTotal",][1:10,]
cropDamageTop10 <- transform(cropDamageTop10, EVTYPE = reorder(EVTYPE, value))
propDamageTop10 <- meltAggregatesEcoSorted[meltAggregatesEcoSorted$variable == "propDmgAmountTotal",][1:10,]
propDamageTop10 <- transform(propDamageTop10, EVTYPE = reorder(EVTYPE, value))
```

Finally, below is the graph for crop damage:
```{r,fig.width=9}
# Crop damage 
gCropDamage <- ggplot(cropDamageTop10, aes(x=EVTYPE, fill=EVTYPE, y=value / 1000 / 1000)) +
    geom_histogram(stat="identity") +
    coord_flip() +
    ggtitle("10 most damages on crop events in the U.S. from 1950 to 2011") +
    ylab("Amount of damage in Millions of $") +
    xlab("Event type") +
    scale_fill_discrete(name="") +
    scale_y_continuous(labels= comma)
    
gCropDamage
```

Here we can see that the event that has most consequences on crop is the River Flood (`r format(cropDamageTop10$value[1], scientific=FALSE, big.mark=",")` $). Then come the Ice Storm (`r format(cropDamageTop10$value[2], scientific=FALSE, big.mark=",")` $) and the Flood (`r format(cropDamageTop10$value[3], scientific=FALSE, big.mark=",")` $).

Then, below is the graph for property damage. We have cut the FLOOD bar as it is far larger from
the other values:
```{r,fig.width=9}
# Prop damage
gPropDamage <- ggplot(propDamageTop10, aes(x=EVTYPE, fill=EVTYPE, y=value / 1000 / 1000 / 1000)) +
    geom_histogram(stat="identity") +
    coord_flip(ylim=c(0,40)) +
    geom_text(data=propDamageTop10[1,],
              aes(x=EVTYPE,
                  y=20,
                  label=paste(round(value / 1000 / 1000 / 1000, 0), "Billions $"))) +
    ggtitle("10 most damages on property events in the U.S. from 1950 to 2011") +
    ylab("Amount of damage in Billions of $") +
    xlab("Event type") +
    scale_fill_discrete(name="") +
    scale_y_continuous(labels= comma)

gPropDamage
```

Here we can see that Flood has the most consequences on properties with `r propDamageTop10$value[1] / 1000 / 1000 / 1000` Billions of $. Next come Hurricane/Typhoon and Typhoon.

## Further improvements

As we can see, a cleaning of the event types could be done to improve the categorization of data. This has not been done in the scope of this study due to lack of time. But this study is a first step to a more deeper analysis and one of the further steps would be to represent the data on a map and see which states are more impacted by weather events.

## Supplementary info

Below are our environment settings:
```{r}
sessionInfo()
```

